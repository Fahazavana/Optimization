
# Introduction

This repository provide a collection  of optimization algorithm with brief overview and short explanation. It encompas zero, first and second order methods.

It include also some examples with well known Test function used in Optemization. All the code are implemented with python 3 leveraging Numpy and Jax library.

## Requirements:
* JAX
* Numpy
* Matplotlib
* tqdm
* ipywidget
* impl

## Available Algorithms

* Vanilla Gradient Descent
* Adaptive steplength Gradient Descent
* Vanilla Newton's methods
* Newton's Method with pseudo inverse.
* Normalized Gradient Descent
* Adam
* Adagrad
* Momentum Gradient descent
* RMSProp

## Available Test Functions
* Rastrigin
* Sphere
* Ackley
