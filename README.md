# Optimization
A collection of some Optimization algoritms:
* Vanilla Gradient Descent
* Adaptive steplength Gradient Descent
* Vanilla Newton's methods
* Newton's Method with pseudo inverse.
* Normalized Gradient Descent
* Adam
* Adagrad
* Momentum Gradient descent
* RMSProp
